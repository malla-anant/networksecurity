# ğŸ“¡ Network Security Prediction App

> Detect malicious or suspicious URLs using machine learning â€” upload a CSV of URL features, and get predictions instantly.

---

## ğŸŒ Live Demo / Web App

You can try the deployed app here:  
**[ğŸ›¡ï¸ Network Security Prediction App â€“ Streamlit Cloud]([(https://malla-anant-networksecurity-streamlit-app-ri7wmo.streamlit.app/)])**

---

## ğŸ§  Project Overview

This project is designed to classify URLs as benign or malicious using machine learning. It includes:

- A **data pipeline**: ingestion â†’ validation â†’ transformation  
- **Model training** module for ML model development  
- **Backend API** using FastAPI for serving predictions  
- **Frontend UI** using Streamlit for easy CSV upload and prediction display  
- Optional **MongoDB integration** for storing data and artifacts  
- Produces output CSV and HTML-table view of predictions  

---

## ğŸ”§ Setup & Run Locally

1. Clone the repository

git clone https://github.com/malla-anant/networksecurity.git
cd networksecurity

2. Create a virtual environment

python -m venv venv
# Windows
venv\Scripts\activate
# macOS / Linux
# source venv/bin/activate

3. Install dependencies

pip install -r requirements.txt

4. Run backend (FastAPI)

# Start the backend using Uvicorn with auto-reload
uvicorn app:app --reload

5. Run frontend (Streamlit)

streamlit run streamlit_app.py
Visit: http://localhost:8501

Upload a CSV of URL features â†’ Click Predict â†’ See results in table + download option

ğŸ§ª Input / Output Format

Input: CSV file where each row has feature columns like:
having_IP_Address, URL_Length, Shortining_Service, having_At_Symbol, ...

Output: Same data plus a new column predicted_column (e.g., 1.0 for malicious, 0.0 for benign).
Output is shown in table in UI; also saved in prediction_output/output.csv.

ğŸ›  Technologies & Libraries

Python 3.x
FastAPI â€” backend API
Streamlit â€” frontend UI
Pandas, NumPy, scikit-learn â€” data & ML
MongoDB â€” optional for data storage
Jinja2 â€” HTML templating for backend
Includes custom modules for logging, exception handling, and ML pipelines.

ğŸš€ Deployment â€” Streamlit Community Cloud

Make sure your repo has streamlit_app.py, requirements.txt, and all required files.
Push changes to GitHub main branch.
Go to Streamlit Cloud â†’ New app â†’ pick your repo, branch & file â†’ Deploy.
Once deployed, copy the public URL and update the Live Demo link above.

ğŸ“ Notes & Tips

Ensure your trained model and preprocessor files are present under final_model/.
Input CSV must match the feature schema expected by the model.
Dependencies are managed via requirements.txt.

ğŸ‘¤ Author
Malla Anant
